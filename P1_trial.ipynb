{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T17:22:29.856194Z",
     "start_time": "2019-08-27T17:22:28.504835Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('news_chinese.csv')\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 获得所有表示“说”的意思的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T16:56:04.396204Z",
     "start_time": "2019-08-27T16:56:04.197205Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = '.\\\\ltp_data_v3.4.0\\\\'  # ltp模型目录的路径\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n",
    "\n",
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load(cws_model_path)  # 加载模型\n",
    "\n",
    "def cut_words(text):\n",
    "    words = segmentor.segment(text)  # 分词\n",
    "    return words\n",
    "#     segmentor.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T17:20:02.262676Z",
     "start_time": "2019-08-27T17:20:02.257707Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyltp import SentenceSplitter\n",
    "\n",
    "def split_sentence(text):\n",
    "    '''\n",
    "    split text into single sentence without '\\n'\n",
    "    '''\n",
    "    sentences = []\n",
    "    try:\n",
    "        sentence_list = text.split('\\\\n')\n",
    "        for sentence in sentence_list:\n",
    "            splited_sentence = SentenceSplitter.split(sentence)  # 分句\n",
    "            sentences.extend(list(splited_sentence))\n",
    "    except Exception:\n",
    "        print('split_sentence exception:' + str(text))\n",
    "        print(Exception)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T17:00:52.305342Z",
     "start_time": "2019-08-27T17:00:52.301341Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    preprocess text, drop number, blank, stopwords\n",
    "    return segments list\n",
    "    \"\"\"\n",
    "#     stopwords=pd.read_csv('.\\\\stopwords.txt',index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "#     stopwords=stopwords['stopword'].values\n",
    "    if len(text) == 1:\n",
    "        return ''\n",
    "    \n",
    "    try:\n",
    "        segs = list(cut_words(text))\n",
    "#         segs = [v for v in segs if not str(v).isdigit()]#去数字\n",
    "        segs = list(filter(lambda x:x.strip(), segs)) #去左右空格\n",
    "#         segs = list(filter(lambda x:len(x)>1, segs))#长度为1的字符\n",
    "#         segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词\n",
    "    except Exception:\n",
    "        print('preprocess_text exception:' + str(text))\n",
    "        print(Exception)\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T17:25:20.492826Z",
     "start_time": "2019-08-27T17:22:50.281775Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "preprocess and write corpus to file for future use\n",
    "'''\n",
    "with open('corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    for graph in data['content'].values:\n",
    "        sentences = split_sentence(graph)  # 分句\n",
    "        for sentence in sentences:\n",
    "            words = preprocess_text(sentence)\n",
    "            if words == '':\n",
    "                continue\n",
    "            f.write(' '.join(words))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T17:44:09.938215Z",
     "start_time": "2019-08-27T17:41:54.444315Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "E:\\Anaconda3\\envs\\py36\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "corpus = LineSentence('corpus.txt')\n",
    "'''\n",
    "LineSentence(inp)：格式简单：一句话=一行; 单词已经过预处理并被空格分隔。\n",
    "size：是每个词的向量维度； \n",
    "window：是词向量训练时的上下文扫描窗口大小，窗口为5就是考虑前5个词和后5个词； \n",
    "min-count：设置最低频率，默认是5，如果一个词语在文档中出现的次数小于5，那么就会丢弃； \n",
    "workers：是训练的进程数（需要更精准的解释，请指正），默认是当前运行机器的处理器核数。这些参数先记住就可以了。\n",
    "sg ({0, 1}, optional) – 模型的训练算法: 1: skip-gram; 0: CBOW\n",
    "alpha (float, optional) – 初始学习率\n",
    "iter (int, optional) – 迭代次数，默认为5\n",
    "'''\n",
    "model = Word2Vec(sentences=corpus, size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "model.save(\".\\\\word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.20866792,  0.7205171 , -1.0260113 , -0.06374749,  0.19556347,\n",
       "       -0.10682994, -0.5851775 , -0.01481899,  0.3670453 ,  0.24029326,\n",
       "        0.5949725 ,  0.28039786, -0.06872837, -0.33250424, -0.1844618 ,\n",
       "       -0.5172169 ,  0.34398785, -0.58655286, -0.1243936 , -0.75491464,\n",
       "        0.09888597,  0.40916127,  0.10244063,  0.7225233 ,  0.32497236,\n",
       "        0.56063825,  0.8444974 , -0.3222012 ,  0.34923565,  0.27028653,\n",
       "       -0.51589775, -0.5600994 ,  0.2264611 , -0.385016  , -0.4579577 ,\n",
       "        0.08523443,  0.64386386, -0.10020302, -0.01174884, -0.51918715,\n",
       "       -0.01156036, -0.22992441,  0.77415377,  0.05849807, -0.2401069 ,\n",
       "       -0.00274309, -0.7530591 ,  0.07110906, -0.13691097,  0.1307326 ,\n",
       "       -0.49360964, -0.21363465,  0.7133124 ,  0.357119  ,  0.47492936,\n",
       "       -0.23782545,  1.0265316 , -0.13638072, -0.27368957, -0.03718648,\n",
       "        0.7090336 , -0.76925814, -0.48834   ,  0.71585935,  0.19875243,\n",
       "       -0.85786104,  0.28460357, -0.29654166, -0.14113064,  0.8782624 ,\n",
       "       -0.11440696,  0.20456931, -0.24379306,  0.80188143,  0.19253168,\n",
       "        0.04655569, -0.82315147,  0.13960767,  0.06716272, -0.46724465,\n",
       "       -0.02533841, -0.47917455, -0.6083708 ,  0.75265986,  0.12438376,\n",
       "       -0.4198804 , -0.04766526,  0.38098052,  0.37672096,  0.706703  ,\n",
       "       -0.44198063, -0.8817988 , -0.20643437,  0.16330408,  0.51761544,\n",
       "       -0.37391335,  0.09321438,  0.38813108, -0.32184866, -0.31084642],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['说']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 找相似词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding Tutorial: word2vec using Gensim\n",
    "\n",
    "https://www.guru99.com/word-embedding-word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223587"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(model.wv.vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('表示', 0.8703572750091553), ('告诉', 0.8542202115058899), ('指出', 0.7788625955581665), ('认为', 0.7690681219100952), ('说道', 0.7643224000930786), ('坦言', 0.7485840916633606), ('介绍', 0.7473160624504089), ('看来', 0.7389413118362427), ('透露', 0.6973441243171692), ('写道', 0.6708030104637146)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.most_similar('说')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the similarity between these two words:\n",
      "0.4619258715508007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "similarity_two_words = model.similarity('说','讲')\n",
    "print(\"Please provide the similarity between these two words:\")\n",
    "print(similarity_two_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('表示', 0.8703572750091553), ('告诉', 0.8542202115058899), ('指出', 0.7788625955581665), ('认为', 0.7690681219100952), ('说道', 0.7643224000930786), ('坦言', 0.7485840916633606), ('介绍', 0.7473160624504089), ('看来', 0.7389413118362427), ('透露', 0.6973441243171692), ('写道', 0.6708030104637146)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "similar = model.similar_by_word('说')\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
